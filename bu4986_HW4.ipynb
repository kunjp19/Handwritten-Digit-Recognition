{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split,KFold,RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.neural_network import multilayer_perceptron,MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV,PredefinedSplit\n",
    "from sklearn.feature_selection import SelectKBest,chi2,SelectFromModel\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2)\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q1 [3.5pts]</b>: <br/>Implement the logistic regression (i.e. 1 layer neural network with a\n",
    "single sigmoidal output) algorithm yourself in Python, use adaptive learning rate\n",
    "and momentum for training. Train and test 10 times, each time, start from different\n",
    "random initial weights and use a random subset of 80% of the training data and also\n",
    "start with a different initial learning rate (e.g. 0.0001, 0.005, 0.001, 0.01 etc.) and\n",
    "momentum (0.9, 0.95, 0.99). Report the total training and test errors for each of the\n",
    "10 runs. Report also the initial learning rate and the momentum you used.\n",
    "Note that you need to replace the 7s in the target column with 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t=pd.read_csv(\"optdigits.tra\",header=None)\n",
    "data_t=data_t[((data_t.iloc[:,-1]==1) | (data_t.iloc[:,-1]==7))]\n",
    "data_t.replace({7:0},inplace=True)\n",
    "Dimensions=64\n",
    "models=[]\n",
    "data_p=[]\n",
    "kFold=KFold(n_splits=10,shuffle=True,random_state=2)\n",
    "for train_index,test_index in kFold.split(data_t):\n",
    "    data_p.append((data_t.iloc[train_index,:-1].values,data_t.iloc[train_index,-1].values,data_t.iloc[test_index,:-1].values,data_t.iloc[test_index,-1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self,lr_rate,momentum,dimensions,p,q):\n",
    "        self.lr_rate=lr_rate\n",
    "        self.momentum=momentum\n",
    "        self.dimensions=dimensions\n",
    "        self.weights=np.random.uniform(low=0,high=0.0005,size=(dimensions,1))\n",
    "        self.p=p\n",
    "        self.q=q\n",
    "    def Print_Model_Params(self,i):\n",
    "        print(\"*\"*70)\n",
    "        print(\"Run:{0}\\nInitial learning rate:{1}\\nInitial momentum:{2}\".format(i,self.lr_rate,self.momentum))\n",
    "    def sigmoid_function(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def cross_entropy(self,y_true,y_pred):\n",
    "        return log_loss(y_true,y_pred)\n",
    "    def train(self,x_train,y_train,n_iter=50):\n",
    "        err=[]\n",
    "        converged=False\n",
    "        while converged==False and n_iter!=0:\n",
    "            error=0\n",
    "            n_iter-=1\n",
    "            predictions=[]\n",
    "            temp=np.zeros(shape=(self.dimensions))\n",
    "            d_weights=np.zeros(shape=(self.dimensions))\n",
    "            for i in range(x_train.shape[0]):\n",
    "                O=0\n",
    "                for j in range(x_train.shape[1]):\n",
    "                    O+=(self.weights[j]*x_train[i,j])\n",
    "                y_pred=self.sigmoid_function(O)\n",
    "                for j in range(x_train.shape[1]):\n",
    "                    d_weights[j]=(self.lr_rate*(y_train[i]-y_pred)*x_train[i,j])+(self.momentum*d_weights[j])\n",
    "                predictions.append(y_train[i]-y_pred)\n",
    "            isDecreasing=True\n",
    "            err.append(self.cross_entropy(y_train,np.array(predictions)))\n",
    "            curr_error=err[-1]\n",
    "            for i in range(len(err)-1):\n",
    "                if err[i]<=curr_error:\n",
    "                    isDecreasing=False\n",
    "                    break\n",
    "            if isDecreasing:\n",
    "                self.lr_rate+=self.p\n",
    "            else:\n",
    "                self.lr_rate-=(self.q*self.lr_rate)\n",
    "            for j in range(self.dimensions):\n",
    "                self.weights[j]+=(d_weights[j])\n",
    "            try:\n",
    "                if err[-2]==err[-1]:\n",
    "                    converged=True\n",
    "            except IndexError:\n",
    "                continue\n",
    "        self.evaluate(\"Training\",y_train,self.predict(x_train))\n",
    "    def predict(self,x):\n",
    "        y_pred=self.sigmoid_function(np.sum(x*self.weights.T,axis=1))\n",
    "        y_pred=np.array(y_pred>0.5,dtype=np.int16)\n",
    "        return y_pred\n",
    "    def evaluate(self,string,y_true,y_pred):\n",
    "        print(\"{0} error rate for this run :{1}\".format(string,1-accuracy_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0004923954119278034\n",
      "Initial momentum:0.9012963115913946\n",
      "Training error rate for this run :0.015759312320916874\n",
      "Test error rate for this run :0.012820512820512775\n",
      "**********************************************************************\n",
      "Run:1\n",
      "Initial learning rate:0.000420961853010483\n",
      "Initial momentum:0.90228394826227\n",
      "Training error rate for this run :0.017191977077363862\n",
      "Test error rate for this run :0.0\n",
      "**********************************************************************\n",
      "Run:2\n",
      "Initial learning rate:0.0002934319457176257\n",
      "Initial momentum:0.9142801866955451\n",
      "Training error rate for this run :0.015759312320916874\n",
      "Test error rate for this run :0.012820512820512775\n",
      "**********************************************************************\n",
      "Run:3\n",
      "Initial learning rate:0.0009250431507620943\n",
      "Initial momentum:0.9351132120409862\n",
      "Training error rate for this run :0.012893982808022897\n",
      "Test error rate for this run :0.012820512820512775\n",
      "**********************************************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0002580391638179397\n",
      "Initial momentum:0.9356660781078705\n",
      "Training error rate for this run :0.015759312320916874\n",
      "Test error rate for this run :0.012820512820512775\n",
      "**********************************************************************\n",
      "Run:5\n",
      "Initial learning rate:0.0002823841462129514\n",
      "Initial momentum:0.9031450770090421\n",
      "Training error rate for this run :0.017191977077363862\n",
      "Test error rate for this run :0.038461538461538436\n",
      "**********************************************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0008883460651816281\n",
      "Initial momentum:0.9009379073385383\n",
      "Training error rate for this run :0.024320457796852657\n",
      "Test error rate for this run :0.025974025974025983\n",
      "**********************************************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0006882506662717056\n",
      "Initial momentum:0.9439643477708577\n",
      "Training error rate for this run :0.012875536480686733\n",
      "Test error rate for this run :0.012987012987012991\n",
      "**********************************************************************\n",
      "Run:8\n",
      "Initial learning rate:0.0003165078199704064\n",
      "Initial momentum:0.9006951912592343\n",
      "Training error rate for this run :0.03147353361945637\n",
      "Test error rate for this run :0.012987012987012991\n",
      "**********************************************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0003707935420446902\n",
      "Initial momentum:0.9289925362678241\n",
      "Training error rate for this run :0.012875536480686733\n",
      "Test error rate for this run :0.012987012987012991\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    lr_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.95)\n",
    "    model=Logistic_Regression(lr_rate,momentum,Dimensions,0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_p[i]\n",
    "    model.Print_Model_Params(i)\n",
    "    model.train(x_train,y_train,10)\n",
    "    models.append(model)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2 [2pts]:</b><br/> Using the 10 runs in Q1, for each feature compute feature importance as\n",
    "the average of the absolute value of the logistic regression model weight connected\n",
    "to that specific feature.<br/>\n",
    "Eliminate 10%, 25%, 50% of the least important features and train and test again\n",
    "with the same training instances (but with the features you selected) as in Q1.\n",
    "Report and training and test errors for each of the 10 runs and three different levels\n",
    "of feature selection.<br/><br/>\n",
    "Did feature selection help?<br/>\n",
    "Yes,having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.<br/>\n",
    "\n",
    "Which features were eliminated for 10% elimination and is there a reason why they\n",
    "were eliminated?<br/>\n",
    "Features having more number of indices zeros are eliminate becouse having a lot of zeros does not necessarily mean you have zero inflation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_weights=[]\n",
    "for model in models:\n",
    "    Average_weights.append(np.abs(model.weights))\n",
    "Average_weights=np.array(Average_weights)\n",
    "Average_weights=Average_weights.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eliminating_ft_10=Average_weights.argsort(axis = 0)[:int(0.9*Dimensions)]\n",
    "Eliminating_ft_25=Average_weights.argsort(axis = 0)[:int(0.75*Dimensions)]\n",
    "Eliminating_ft_50=Average_weights.argsort(axis = 0)[:int(0.5*Dimensions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0008699886819074396\n",
      "Initial momentum:0.9180176709412956\n",
      "Training error rate for this run :0.3194842406876791\n",
      "Test error rate for this run :0.3589743589743589\n",
      "**********************************************************************\n",
      "Run:1\n",
      "Initial learning rate:0.0008310286747364229\n",
      "Initial momentum:0.9042416709506133\n",
      "Training error rate for this run :0.2664756446991404\n",
      "Test error rate for this run :0.2435897435897436\n",
      "**********************************************************************\n",
      "Run:2\n",
      "Initial learning rate:0.0009318874924911064\n",
      "Initial momentum:0.9488630617509457\n",
      "Training error rate for this run :0.33954154727793695\n",
      "Test error rate for this run :0.2948717948717948\n",
      "**********************************************************************\n",
      "Run:3\n",
      "Initial learning rate:0.00034884516528538263\n",
      "Initial momentum:0.9648582591187477\n",
      "Training error rate for this run :0.26361031518624645\n",
      "Test error rate for this run :0.21794871794871795\n",
      "**********************************************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0003705070946890872\n",
      "Initial momentum:0.9818843486442089\n",
      "Training error rate for this run :0.3237822349570201\n",
      "Test error rate for this run :0.3589743589743589\n",
      "**********************************************************************\n",
      "Run:5\n",
      "Initial learning rate:0.00017280080960728413\n",
      "Initial momentum:0.9511100962750636\n",
      "Training error rate for this run :0.44126074498567336\n",
      "Test error rate for this run :0.3717948717948718\n",
      "**********************************************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0002306400674477947\n",
      "Initial momentum:0.9356016142326387\n",
      "Training error rate for this run :0.4735336194563662\n",
      "Test error rate for this run :0.5844155844155844\n",
      "**********************************************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0009816039585296202\n",
      "Initial momentum:0.9597168645349453\n",
      "Training error rate for this run :0.2689556509298998\n",
      "Test error rate for this run :0.3246753246753247\n",
      "**********************************************************************\n",
      "Run:8\n",
      "Initial learning rate:0.00040883998280476333\n",
      "Initial momentum:0.9250116771470961\n",
      "Training error rate for this run :0.2103004291845494\n",
      "Test error rate for this run :0.23376623376623373\n",
      "**********************************************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0009704735316824693\n",
      "Initial momentum:0.9482041251738751\n",
      "Training error rate for this run :0.27896995708154504\n",
      "Test error rate for this run :0.3116883116883117\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    lr_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=Logistic_Regression(lr_rate,momentum,Eliminating_ft_10.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_p[i]\n",
    "    model.Print_Model_Params(i)\n",
    "    model.train(x_train[:,Eliminating_ft_10].reshape(x_train.shape[0],Eliminating_ft_10.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,Eliminating_ft_10].reshape(x_test.shape[0],Eliminating_ft_10.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0007468674923132592\n",
      "Initial momentum:0.9101830306927032\n",
      "Training error rate for this run :0.47851002865329517\n",
      "Test error rate for this run :0.5\n",
      "**********************************************************************\n",
      "Run:1\n",
      "Initial learning rate:0.0008951181896967383\n",
      "Initial momentum:0.9762157598538008\n",
      "Training error rate for this run :0.42836676217765046\n",
      "Test error rate for this run :0.4358974358974359\n",
      "**********************************************************************\n",
      "Run:2\n",
      "Initial learning rate:0.0003913870158216833\n",
      "Initial momentum:0.912420232790289\n",
      "Training error rate for this run :0.4842406876790831\n",
      "Test error rate for this run :0.42307692307692313\n",
      "**********************************************************************\n",
      "Run:3\n",
      "Initial learning rate:0.00010884087127594955\n",
      "Initial momentum:0.9037609004038181\n",
      "Training error rate for this run :0.21060171919770776\n",
      "Test error rate for this run :0.23076923076923073\n",
      "**********************************************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0009683528794368668\n",
      "Initial momentum:0.9556771626906446\n",
      "Training error rate for this run :0.4212034383954155\n",
      "Test error rate for this run :0.5512820512820513\n",
      "**********************************************************************\n",
      "Run:5\n",
      "Initial learning rate:0.00039925949841760076\n",
      "Initial momentum:0.9100629603350909\n",
      "Training error rate for this run :0.47994269340974216\n",
      "Test error rate for this run :0.39743589743589747\n",
      "**********************************************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0008386462128664847\n",
      "Initial momentum:0.9461681919720368\n",
      "Training error rate for this run :0.44921316165951364\n",
      "Test error rate for this run :0.3246753246753247\n",
      "**********************************************************************\n",
      "Run:7\n",
      "Initial learning rate:0.00033823283800935597\n",
      "Initial momentum:0.9061747648038082\n",
      "Training error rate for this run :0.18168812589413452\n",
      "Test error rate for this run :0.16883116883116878\n",
      "**********************************************************************\n",
      "Run:8\n",
      "Initial learning rate:0.00044345768740011195\n",
      "Initial momentum:0.9610948029965648\n",
      "Training error rate for this run :0.1688125894134478\n",
      "Test error rate for this run :0.18181818181818177\n",
      "**********************************************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0005321980367364836\n",
      "Initial momentum:0.9296415526846751\n",
      "Training error rate for this run :0.4391988555078684\n",
      "Test error rate for this run :0.4285714285714286\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    lr_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=Logistic_Regression(lr_rate,momentum,Eliminating_ft_25.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_p[i]\n",
    "    model.Print_Model_Params(i)\n",
    "    model.train(x_train[:,Eliminating_ft_25].reshape(x_train.shape[0],Eliminating_ft_25.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,Eliminating_ft_25].reshape(x_test.shape[0],Eliminating_ft_25.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Run:0\n",
      "Initial learning rate:0.0009303725582888083\n",
      "Initial momentum:0.9170287747345163\n",
      "Training error rate for this run :0.498567335243553\n",
      "Test error rate for this run :0.46153846153846156\n",
      "**********************************************************************\n",
      "Run:1\n",
      "Initial learning rate:0.0005293172721071327\n",
      "Initial momentum:0.9121856035892043\n",
      "Training error rate for this run :0.44269340974212035\n",
      "Test error rate for this run :0.47435897435897434\n",
      "**********************************************************************\n",
      "Run:2\n",
      "Initial learning rate:0.0005286262664736112\n",
      "Initial momentum:0.9190968524630521\n",
      "Training error rate for this run :0.4455587392550143\n",
      "Test error rate for this run :0.5256410256410257\n",
      "**********************************************************************\n",
      "Run:3\n",
      "Initial learning rate:0.000544734367997459\n",
      "Initial momentum:0.9425738981319378\n",
      "Training error rate for this run :0.33810888252148996\n",
      "Test error rate for this run :0.3205128205128205\n",
      "**********************************************************************\n",
      "Run:4\n",
      "Initial learning rate:0.0005399547835112365\n",
      "Initial momentum:0.9871099467941512\n",
      "Training error rate for this run :0.3939828080229226\n",
      "Test error rate for this run :0.3076923076923077\n",
      "**********************************************************************\n",
      "Run:5\n",
      "Initial learning rate:0.0006803090050759383\n",
      "Initial momentum:0.9203323354509831\n",
      "Training error rate for this run :0.49283667621776506\n",
      "Test error rate for this run :0.42307692307692313\n",
      "**********************************************************************\n",
      "Run:6\n",
      "Initial learning rate:0.0001859196670618213\n",
      "Initial momentum:0.9605267917654019\n",
      "Training error rate for this run :0.42060085836909866\n",
      "Test error rate for this run :0.4415584415584416\n",
      "**********************************************************************\n",
      "Run:7\n",
      "Initial learning rate:0.0005238193774848404\n",
      "Initial momentum:0.9361355330589016\n",
      "Training error rate for this run :0.4334763948497854\n",
      "Test error rate for this run :0.4415584415584416\n",
      "**********************************************************************\n",
      "Run:8\n",
      "Initial learning rate:0.00041401293009509004\n",
      "Initial momentum:0.9435276645561436\n",
      "Training error rate for this run :0.4835479256080114\n",
      "Test error rate for this run :0.49350649350649356\n",
      "**********************************************************************\n",
      "Run:9\n",
      "Initial learning rate:0.0009695169355117579\n",
      "Initial momentum:0.9424636871584844\n",
      "Training error rate for this run :0.49642346208869814\n",
      "Test error rate for this run :0.5064935064935066\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    lr_rate=np.random.uniform(low=0.0001,high=0.001)\n",
    "    momentum=np.random.uniform(low=0.9,high=0.99)\n",
    "    model=Logistic_Regression(lr_rate,momentum,Eliminating_ft_50.shape[0],0.0001,0.0002)\n",
    "    x_train,y_train,x_test,y_test=data_p[i]\n",
    "    model.Print_Model_Params(i)\n",
    "    model.train(x_train[:,Eliminating_ft_50].reshape(x_train.shape[0],Eliminating_ft_50.shape[0]),y_train,10)\n",
    "    model.evaluate(\"Test\",y_test,model.predict(x_test[:,Eliminating_ft_50].reshape(x_test.shape[0],Eliminating_ft_50.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3 [2pts]:</b> <br/> Use the scikit-learn neural network implementation to train a neural\n",
    "network and test it using the same instances as in Q1. Increase the test error as\n",
    "much as you can through selection of:<br/>\n",
    "-different number of hidden layers and units,<br/>\n",
    "-L1 or L2 regularization/weight decay,<br/>\n",
    "-different optimization algorithms,<br/>\n",
    "-feature selection, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 0\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 2\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 3\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 5\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 6\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 7\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 8\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 9\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test scores  \\\n",
      "0     0.000000   \n",
      "1     0.500000   \n",
      "2     0.000000   \n",
      "3     0.000000   \n",
      "4     0.012821   \n",
      "5     0.025641   \n",
      "6     0.000000   \n",
      "7     0.000000   \n",
      "8     0.012987   \n",
      "9     0.000000   \n",
      "\n",
      "                                                                    params  \\\n",
      "0    {'alpha': 0.001, 'hidden_layer_sizes': (100, 10, 2), 'solver': 'sgd'}   \n",
      "1  {'alpha': 0.0001, 'hidden_layer_sizes': (100, 10, 2), 'solver': 'adam'}   \n",
      "2     {'alpha': 1e-05, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'sgd'}   \n",
      "3     {'alpha': 0.001, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'sgd'}   \n",
      "4    {'alpha': 1e-05, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'adam'}   \n",
      "5    {'alpha': 0.0001, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'sgd'}   \n",
      "6   {'alpha': 0.001, 'hidden_layer_sizes': (100, 10, 2), 'solver': 'adam'}   \n",
      "7      {'alpha': 0.1, 'hidden_layer_sizes': (100, 10, 2), 'solver': 'sgd'}   \n",
      "8   {'alpha': 0.0001, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'adam'}   \n",
      "9   {'alpha': 0.0001, 'hidden_layer_sizes': (30, 10, 2), 'solver': 'adam'}   \n",
      "\n",
      "   Test error for K Best feature selection  \\\n",
      "0                                 0.000000   \n",
      "1                                 0.012821   \n",
      "2                                 0.012821   \n",
      "3                                 0.461538   \n",
      "4                                 0.000000   \n",
      "5                                 0.012821   \n",
      "6                                 0.584416   \n",
      "7                                 0.012987   \n",
      "8                                 0.012987   \n",
      "9                                 0.493506   \n",
      "\n",
      "   Test error for Tree based selection  \n",
      "0                             0.000000  \n",
      "1                             0.012821  \n",
      "2                             0.012821  \n",
      "3                             0.000000  \n",
      "4                             0.025641  \n",
      "5                             0.423077  \n",
      "6                             0.012987  \n",
      "7                             0.012987  \n",
      "8                             0.012987  \n",
      "9                             0.000000  \n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'hidden_layer_sizes':[(10,20),(50,30),(100,10,2),(30,10,2)],\n",
    "    'solver':['adam','sgd'],\n",
    "    'alpha':[0.0001,0.00001,0.001,0.1]\n",
    "}\n",
    "sk_models=[]\n",
    "w_parameters=[]\n",
    "scores=[]\n",
    "k_best=[]\n",
    "tree_selection=[]\n",
    "for i,(x_train,y_train,x_test,y_test) in enumerate(data_p):\n",
    "    print(\"\\nRun {0}\".format(i))\n",
    "    model=GridSearchCV(MLPClassifier(),param_grid=params,n_jobs=-1,cv=RepeatedKFold(n_splits=2,n_repeats=1,random_state=2),verbose=3,scoring='neg_log_loss')\n",
    "    model.fit(x_train,y_train)\n",
    "    w_t_error=model.cv_results_['mean_test_score']\n",
    "    w_parameters.append(model.cv_results_['params'][np.argmin(w_t_error)])\n",
    "    test_model=MLPClassifier(**w_parameters[-1])\n",
    "    test_model.fit(x_train,y_train)\n",
    "    w_t_error=model.cv_results_['mean_test_score']\n",
    "    \n",
    "    scores.append(1-accuracy_score(y_test,test_model.predict(x_test)))\n",
    "    selector=SelectKBest(chi2,k=45)\n",
    "    x_train_=selector.fit_transform(x_train,y_train)\n",
    "    x_test_=selector.transform(x_test)\n",
    "    test_model.fit(x_train_,y_train)\n",
    "    k_best.append(1-accuracy_score(y_test,test_model.predict(x_test_)))\n",
    "    \n",
    "    selector=SelectFromModel(SVC(kernel='linear'))\n",
    "    x_train_=selector.fit_transform(x_train,y_train)\n",
    "    x_test_=selector.transform(x_test)\n",
    "    test_model.fit(x_train_,y_train)\n",
    "    tree_selection.append(1-accuracy_score(y_test,test_model.predict(x_test_)))\n",
    "    \n",
    "    sk_models.append(model)\n",
    "scores=np.array(scores)\n",
    "w_parameters=np.array(w_parameters)\n",
    "df=pd.DataFrame({\"Test scores\":scores,\"params\":w_parameters,\"Test error for K Best feature selection\":k_best,\"Test error for Tree based selection\":tree_selection})\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
